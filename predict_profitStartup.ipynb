{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vC5WqnedfxY"
   },
   "source": [
    "You are hired by a venture capitalist to predict the profit of a startup. Fo that you have to deal with a dataset which contains the details of 50 startupâ€™s and predicts the profit of a new Startup based on certain features. Based on your decision and prediction, whether one should invest in a particular startup or not.\n",
    "\n",
    "Dataset contains the following fields: \n",
    "R&D Stend - Total amount of money spent on Research and Development Administration - Total amount of money spent on Administration \n",
    "Marketing Spend - Total amount of money spent on Markeing \n",
    "State - The state where the startup operates \n",
    "Profit - Profit earned by startup\n",
    "\n",
    "You have to perform following task before applying machine learning algorithms: \n",
    "1) Handle missing values \n",
    "2) Prepare data for training and testing\n",
    "3) Apply Decision Tree algorithm to train the model\n",
    "4) Apply Random Forest Regressor algorithm to train the model\n",
    "5) Compare the accuracy with Linear Regression too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "6lR8tV62dfxY"
   },
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6Dpu0nXadfxY"
   },
   "outputs": [],
   "source": [
    "#loading data file\n",
    "data = pd.read_csv('50_Startups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "oiebWqQ_dfxY",
    "outputId": "89749d5d-302c-4701-91b3-e9bd310e7e2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   R&D Spend        50 non-null     float64\n",
      " 1   Administration   50 non-null     float64\n",
      " 2   Marketing Spend  50 non-null     float64\n",
      " 3   State            50 non-null     object \n",
      " 4   Profit           50 non-null     float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 2.1+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   R&D Spend        50 non-null     float64\n",
      " 1   Administration   50 non-null     float64\n",
      " 2   Marketing Spend  50 non-null     float64\n",
      " 3   State            50 non-null     object \n",
      " 4   Profit           50 non-null     float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#displays number of columns and records/rows in dataset\n",
    "#check if there is any missing data or not\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Lo44s7DndfxZ",
    "outputId": "c5767812-1bf4-414b-f01b-980851504143"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "           R&D Spend  Administration  Marketing Spend         Profit\ncount      50.000000       50.000000        50.000000      50.000000\nmean    73721.615600   121344.639600    211025.097800  112012.639200\nstd     45902.256482    28017.802755    122290.310726   40306.180338\nmin         0.000000    51283.140000         0.000000   14681.400000\n25%     39936.370000   103730.875000    129300.132500   90138.902500\n50%     73051.080000   122699.795000    212716.240000  107978.190000\n75%    101602.800000   144842.180000    299469.085000  139765.977500\nmax    165349.200000   182645.560000    471784.100000  192261.830000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>R&amp;D Spend</th>\n      <th>Administration</th>\n      <th>Marketing Spend</th>\n      <th>Profit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>50.000000</td>\n      <td>50.000000</td>\n      <td>50.000000</td>\n      <td>50.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>73721.615600</td>\n      <td>121344.639600</td>\n      <td>211025.097800</td>\n      <td>112012.639200</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>45902.256482</td>\n      <td>28017.802755</td>\n      <td>122290.310726</td>\n      <td>40306.180338</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>51283.140000</td>\n      <td>0.000000</td>\n      <td>14681.400000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>39936.370000</td>\n      <td>103730.875000</td>\n      <td>129300.132500</td>\n      <td>90138.902500</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>73051.080000</td>\n      <td>122699.795000</td>\n      <td>212716.240000</td>\n      <td>107978.190000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>101602.800000</td>\n      <td>144842.180000</td>\n      <td>299469.085000</td>\n      <td>139765.977500</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>165349.200000</td>\n      <td>182645.560000</td>\n      <td>471784.100000</td>\n      <td>192261.830000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "           R&D Spend  Administration  Marketing Spend         Profit\ncount      50.000000       50.000000        50.000000      50.000000\nmean    73721.615600   121344.639600    211025.097800  112012.639200\nstd     45902.256482    28017.802755    122290.310726   40306.180338\nmin         0.000000    51283.140000         0.000000   14681.400000\n25%     39936.370000   103730.875000    129300.132500   90138.902500\n50%     73051.080000   122699.795000    212716.240000  107978.190000\n75%    101602.800000   144842.180000    299469.085000  139765.977500\nmax    165349.200000   182645.560000    471784.100000  192261.830000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>R&amp;D Spend</th>\n      <th>Administration</th>\n      <th>Marketing Spend</th>\n      <th>Profit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>50.000000</td>\n      <td>50.000000</td>\n      <td>50.000000</td>\n      <td>50.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>73721.615600</td>\n      <td>121344.639600</td>\n      <td>211025.097800</td>\n      <td>112012.639200</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>45902.256482</td>\n      <td>28017.802755</td>\n      <td>122290.310726</td>\n      <td>40306.180338</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>51283.140000</td>\n      <td>0.000000</td>\n      <td>14681.400000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>39936.370000</td>\n      <td>103730.875000</td>\n      <td>129300.132500</td>\n      <td>90138.902500</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>73051.080000</td>\n      <td>122699.795000</td>\n      <td>212716.240000</td>\n      <td>107978.190000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>101602.800000</td>\n      <td>144842.180000</td>\n      <td>299469.085000</td>\n      <td>139765.977500</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>165349.200000</td>\n      <td>182645.560000</td>\n      <td>471784.100000</td>\n      <td>192261.830000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "G5SysJQPdfxa"
   },
   "outputs": [],
   "source": [
    "features = data.iloc[:,:-1].values\n",
    "label = data.iloc[:,[-1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "rHpEErZ9dfxa",
    "outputId": "ae4c1d2d-d773-4703-9135-7fc41d89fa7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[165349.2, 136897.8, 471784.1, 'New York'],\n       [162597.7, 151377.59, 443898.53, 'California'],\n       [153441.51, 101145.55, 407934.54, 'Florida'],\n       [144372.41, 118671.85, 383199.62, 'New York'],\n       [142107.34, 91391.77, 366168.42, 'Florida'],\n       [131876.9, 99814.71, 362861.36, 'New York'],\n       [134615.46, 147198.87, 127716.82, 'California'],\n       [130298.13, 145530.06, 323876.68, 'Florida'],\n       [120542.52, 148718.95, 311613.29, 'New York'],\n       [123334.88, 108679.17, 304981.62, 'California'],\n       [101913.08, 110594.11, 229160.95, 'Florida'],\n       [100671.96, 91790.61, 249744.55, 'California'],\n       [93863.75, 127320.38, 249839.44, 'Florida'],\n       [91992.39, 135495.07, 252664.93, 'California'],\n       [119943.24, 156547.42, 256512.92, 'Florida'],\n       [114523.61, 122616.84, 261776.23, 'New York'],\n       [78013.11, 121597.55, 264346.06, 'California'],\n       [94657.16, 145077.58, 282574.31, 'New York'],\n       [91749.16, 114175.79, 294919.57, 'Florida'],\n       [86419.7, 153514.11, 0.0, 'New York'],\n       [76253.86, 113867.3, 298664.47, 'California'],\n       [78389.47, 153773.43, 299737.29, 'New York'],\n       [73994.56, 122782.75, 303319.26, 'Florida'],\n       [67532.53, 105751.03, 304768.73, 'Florida'],\n       [77044.01, 99281.34, 140574.81, 'New York'],\n       [64664.71, 139553.16, 137962.62, 'California'],\n       [75328.87, 144135.98, 134050.07, 'Florida'],\n       [72107.6, 127864.55, 353183.81, 'New York'],\n       [66051.52, 182645.56, 118148.2, 'Florida'],\n       [65605.48, 153032.06, 107138.38, 'New York'],\n       [61994.48, 115641.28, 91131.24, 'Florida'],\n       [61136.38, 152701.92, 88218.23, 'New York'],\n       [63408.86, 129219.61, 46085.25, 'California'],\n       [55493.95, 103057.49, 214634.81, 'Florida'],\n       [46426.07, 157693.92, 210797.67, 'California'],\n       [46014.02, 85047.44, 205517.64, 'New York'],\n       [28663.76, 127056.21, 201126.82, 'Florida'],\n       [44069.95, 51283.14, 197029.42, 'California'],\n       [20229.59, 65947.93, 185265.1, 'New York'],\n       [38558.51, 82982.09, 174999.3, 'California'],\n       [28754.33, 118546.05, 172795.67, 'California'],\n       [27892.92, 84710.77, 164470.71, 'Florida'],\n       [23640.93, 96189.63, 148001.11, 'California'],\n       [15505.73, 127382.3, 35534.17, 'New York'],\n       [22177.74, 154806.14, 28334.72, 'California'],\n       [1000.23, 124153.04, 1903.93, 'New York'],\n       [1315.46, 115816.21, 297114.46, 'Florida'],\n       [0.0, 135426.92, 0.0, 'California'],\n       [542.05, 51743.15, 0.0, 'New York'],\n       [0.0, 116983.8, 45173.06, 'California']], dtype=object)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "array([[165349.2, 136897.8, 471784.1, 'New York'],\n       [162597.7, 151377.59, 443898.53, 'California'],\n       [153441.51, 101145.55, 407934.54, 'Florida'],\n       [144372.41, 118671.85, 383199.62, 'New York'],\n       [142107.34, 91391.77, 366168.42, 'Florida'],\n       [131876.9, 99814.71, 362861.36, 'New York'],\n       [134615.46, 147198.87, 127716.82, 'California'],\n       [130298.13, 145530.06, 323876.68, 'Florida'],\n       [120542.52, 148718.95, 311613.29, 'New York'],\n       [123334.88, 108679.17, 304981.62, 'California'],\n       [101913.08, 110594.11, 229160.95, 'Florida'],\n       [100671.96, 91790.61, 249744.55, 'California'],\n       [93863.75, 127320.38, 249839.44, 'Florida'],\n       [91992.39, 135495.07, 252664.93, 'California'],\n       [119943.24, 156547.42, 256512.92, 'Florida'],\n       [114523.61, 122616.84, 261776.23, 'New York'],\n       [78013.11, 121597.55, 264346.06, 'California'],\n       [94657.16, 145077.58, 282574.31, 'New York'],\n       [91749.16, 114175.79, 294919.57, 'Florida'],\n       [86419.7, 153514.11, 0.0, 'New York'],\n       [76253.86, 113867.3, 298664.47, 'California'],\n       [78389.47, 153773.43, 299737.29, 'New York'],\n       [73994.56, 122782.75, 303319.26, 'Florida'],\n       [67532.53, 105751.03, 304768.73, 'Florida'],\n       [77044.01, 99281.34, 140574.81, 'New York'],\n       [64664.71, 139553.16, 137962.62, 'California'],\n       [75328.87, 144135.98, 134050.07, 'Florida'],\n       [72107.6, 127864.55, 353183.81, 'New York'],\n       [66051.52, 182645.56, 118148.2, 'Florida'],\n       [65605.48, 153032.06, 107138.38, 'New York'],\n       [61994.48, 115641.28, 91131.24, 'Florida'],\n       [61136.38, 152701.92, 88218.23, 'New York'],\n       [63408.86, 129219.61, 46085.25, 'California'],\n       [55493.95, 103057.49, 214634.81, 'Florida'],\n       [46426.07, 157693.92, 210797.67, 'California'],\n       [46014.02, 85047.44, 205517.64, 'New York'],\n       [28663.76, 127056.21, 201126.82, 'Florida'],\n       [44069.95, 51283.14, 197029.42, 'California'],\n       [20229.59, 65947.93, 185265.1, 'New York'],\n       [38558.51, 82982.09, 174999.3, 'California'],\n       [28754.33, 118546.05, 172795.67, 'California'],\n       [27892.92, 84710.77, 164470.71, 'Florida'],\n       [23640.93, 96189.63, 148001.11, 'California'],\n       [15505.73, 127382.3, 35534.17, 'New York'],\n       [22177.74, 154806.14, 28334.72, 'California'],\n       [1000.23, 124153.04, 1903.93, 'New York'],\n       [1315.46, 115816.21, 297114.46, 'Florida'],\n       [0.0, 135426.92, 0.0, 'California'],\n       [542.05, 51743.15, 0.0, 'New York'],\n       [0.0, 116983.8, 45173.06, 'California']], dtype=object)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "b_wVlq18dfxa",
    "outputId": "0f3024bc-bcfb-44b1-de59-8615d6f5ffc0",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.0, 0.0, 1.0, 165349.2, 136897.8, 471784.1],\n       [1.0, 0.0, 0.0, 162597.7, 151377.59, 443898.53],\n       [0.0, 1.0, 0.0, 153441.51, 101145.55, 407934.54],\n       [0.0, 0.0, 1.0, 144372.41, 118671.85, 383199.62],\n       [0.0, 1.0, 0.0, 142107.34, 91391.77, 366168.42],\n       [0.0, 0.0, 1.0, 131876.9, 99814.71, 362861.36],\n       [1.0, 0.0, 0.0, 134615.46, 147198.87, 127716.82],\n       [0.0, 1.0, 0.0, 130298.13, 145530.06, 323876.68],\n       [0.0, 0.0, 1.0, 120542.52, 148718.95, 311613.29],\n       [1.0, 0.0, 0.0, 123334.88, 108679.17, 304981.62],\n       [0.0, 1.0, 0.0, 101913.08, 110594.11, 229160.95],\n       [1.0, 0.0, 0.0, 100671.96, 91790.61, 249744.55],\n       [0.0, 1.0, 0.0, 93863.75, 127320.38, 249839.44],\n       [1.0, 0.0, 0.0, 91992.39, 135495.07, 252664.93],\n       [0.0, 1.0, 0.0, 119943.24, 156547.42, 256512.92],\n       [0.0, 0.0, 1.0, 114523.61, 122616.84, 261776.23],\n       [1.0, 0.0, 0.0, 78013.11, 121597.55, 264346.06],\n       [0.0, 0.0, 1.0, 94657.16, 145077.58, 282574.31],\n       [0.0, 1.0, 0.0, 91749.16, 114175.79, 294919.57],\n       [0.0, 0.0, 1.0, 86419.7, 153514.11, 0.0],\n       [1.0, 0.0, 0.0, 76253.86, 113867.3, 298664.47],\n       [0.0, 0.0, 1.0, 78389.47, 153773.43, 299737.29],\n       [0.0, 1.0, 0.0, 73994.56, 122782.75, 303319.26],\n       [0.0, 1.0, 0.0, 67532.53, 105751.03, 304768.73],\n       [0.0, 0.0, 1.0, 77044.01, 99281.34, 140574.81],\n       [1.0, 0.0, 0.0, 64664.71, 139553.16, 137962.62],\n       [0.0, 1.0, 0.0, 75328.87, 144135.98, 134050.07],\n       [0.0, 0.0, 1.0, 72107.6, 127864.55, 353183.81],\n       [0.0, 1.0, 0.0, 66051.52, 182645.56, 118148.2],\n       [0.0, 0.0, 1.0, 65605.48, 153032.06, 107138.38],\n       [0.0, 1.0, 0.0, 61994.48, 115641.28, 91131.24],\n       [0.0, 0.0, 1.0, 61136.38, 152701.92, 88218.23],\n       [1.0, 0.0, 0.0, 63408.86, 129219.61, 46085.25],\n       [0.0, 1.0, 0.0, 55493.95, 103057.49, 214634.81],\n       [1.0, 0.0, 0.0, 46426.07, 157693.92, 210797.67],\n       [0.0, 0.0, 1.0, 46014.02, 85047.44, 205517.64],\n       [0.0, 1.0, 0.0, 28663.76, 127056.21, 201126.82],\n       [1.0, 0.0, 0.0, 44069.95, 51283.14, 197029.42],\n       [0.0, 0.0, 1.0, 20229.59, 65947.93, 185265.1],\n       [1.0, 0.0, 0.0, 38558.51, 82982.09, 174999.3],\n       [1.0, 0.0, 0.0, 28754.33, 118546.05, 172795.67],\n       [0.0, 1.0, 0.0, 27892.92, 84710.77, 164470.71],\n       [1.0, 0.0, 0.0, 23640.93, 96189.63, 148001.11],\n       [0.0, 0.0, 1.0, 15505.73, 127382.3, 35534.17],\n       [1.0, 0.0, 0.0, 22177.74, 154806.14, 28334.72],\n       [0.0, 0.0, 1.0, 1000.23, 124153.04, 1903.93],\n       [0.0, 1.0, 0.0, 1315.46, 115816.21, 297114.46],\n       [1.0, 0.0, 0.0, 0.0, 135426.92, 0.0],\n       [0.0, 0.0, 1.0, 542.05, 51743.15, 0.0],\n       [1.0, 0.0, 0.0, 0.0, 116983.8, 45173.06]], dtype=object)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "array([[0.0, 0.0, 1.0, 165349.2, 136897.8, 471784.1],\n       [1.0, 0.0, 0.0, 162597.7, 151377.59, 443898.53],\n       [0.0, 1.0, 0.0, 153441.51, 101145.55, 407934.54],\n       [0.0, 0.0, 1.0, 144372.41, 118671.85, 383199.62],\n       [0.0, 1.0, 0.0, 142107.34, 91391.77, 366168.42],\n       [0.0, 0.0, 1.0, 131876.9, 99814.71, 362861.36],\n       [1.0, 0.0, 0.0, 134615.46, 147198.87, 127716.82],\n       [0.0, 1.0, 0.0, 130298.13, 145530.06, 323876.68],\n       [0.0, 0.0, 1.0, 120542.52, 148718.95, 311613.29],\n       [1.0, 0.0, 0.0, 123334.88, 108679.17, 304981.62],\n       [0.0, 1.0, 0.0, 101913.08, 110594.11, 229160.95],\n       [1.0, 0.0, 0.0, 100671.96, 91790.61, 249744.55],\n       [0.0, 1.0, 0.0, 93863.75, 127320.38, 249839.44],\n       [1.0, 0.0, 0.0, 91992.39, 135495.07, 252664.93],\n       [0.0, 1.0, 0.0, 119943.24, 156547.42, 256512.92],\n       [0.0, 0.0, 1.0, 114523.61, 122616.84, 261776.23],\n       [1.0, 0.0, 0.0, 78013.11, 121597.55, 264346.06],\n       [0.0, 0.0, 1.0, 94657.16, 145077.58, 282574.31],\n       [0.0, 1.0, 0.0, 91749.16, 114175.79, 294919.57],\n       [0.0, 0.0, 1.0, 86419.7, 153514.11, 0.0],\n       [1.0, 0.0, 0.0, 76253.86, 113867.3, 298664.47],\n       [0.0, 0.0, 1.0, 78389.47, 153773.43, 299737.29],\n       [0.0, 1.0, 0.0, 73994.56, 122782.75, 303319.26],\n       [0.0, 1.0, 0.0, 67532.53, 105751.03, 304768.73],\n       [0.0, 0.0, 1.0, 77044.01, 99281.34, 140574.81],\n       [1.0, 0.0, 0.0, 64664.71, 139553.16, 137962.62],\n       [0.0, 1.0, 0.0, 75328.87, 144135.98, 134050.07],\n       [0.0, 0.0, 1.0, 72107.6, 127864.55, 353183.81],\n       [0.0, 1.0, 0.0, 66051.52, 182645.56, 118148.2],\n       [0.0, 0.0, 1.0, 65605.48, 153032.06, 107138.38],\n       [0.0, 1.0, 0.0, 61994.48, 115641.28, 91131.24],\n       [0.0, 0.0, 1.0, 61136.38, 152701.92, 88218.23],\n       [1.0, 0.0, 0.0, 63408.86, 129219.61, 46085.25],\n       [0.0, 1.0, 0.0, 55493.95, 103057.49, 214634.81],\n       [1.0, 0.0, 0.0, 46426.07, 157693.92, 210797.67],\n       [0.0, 0.0, 1.0, 46014.02, 85047.44, 205517.64],\n       [0.0, 1.0, 0.0, 28663.76, 127056.21, 201126.82],\n       [1.0, 0.0, 0.0, 44069.95, 51283.14, 197029.42],\n       [0.0, 0.0, 1.0, 20229.59, 65947.93, 185265.1],\n       [1.0, 0.0, 0.0, 38558.51, 82982.09, 174999.3],\n       [1.0, 0.0, 0.0, 28754.33, 118546.05, 172795.67],\n       [0.0, 1.0, 0.0, 27892.92, 84710.77, 164470.71],\n       [1.0, 0.0, 0.0, 23640.93, 96189.63, 148001.11],\n       [0.0, 0.0, 1.0, 15505.73, 127382.3, 35534.17],\n       [1.0, 0.0, 0.0, 22177.74, 154806.14, 28334.72],\n       [0.0, 0.0, 1.0, 1000.23, 124153.04, 1903.93],\n       [0.0, 1.0, 0.0, 1315.46, 115816.21, 297114.46],\n       [1.0, 0.0, 0.0, 0.0, 135426.92, 0.0],\n       [0.0, 0.0, 1.0, 542.05, 51743.15, 0.0],\n       [1.0, 0.0, 0.0, 0.0, 116983.8, 45173.06]], dtype=object)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the categorical features to numerical features as \n",
    "#sklearn works only with numpy array\n",
    "#Instead of label enconding and then onehotencoding, \n",
    "#newer version directly works with onehotencoding using ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "transformer = ColumnTransformer(transformers=[\n",
    "        (\"OneHot\",        # Just a name\n",
    "         OneHotEncoder(), # The transformer class\n",
    "         [3]              # The column(s) to be applied on.\n",
    "         )\n",
    "    ],\n",
    "    remainder='passthrough' # donot apply anything to the remaining columns\n",
    ")\n",
    "features = transformer.fit_transform(features.tolist())\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "68pre3y0dfxa"
   },
   "outputs": [],
   "source": [
    "#converting an object to normal array\n",
    "features = features.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "YPYY8Shidfxa",
    "outputId": "d6a212b0-befa-4696-9cff-e492ede3011a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.6534920e+05,\n        1.3689780e+05, 4.7178410e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.6259770e+05,\n        1.5137759e+05, 4.4389853e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.5344151e+05,\n        1.0114555e+05, 4.0793454e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.4437241e+05,\n        1.1867185e+05, 3.8319962e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.4210734e+05,\n        9.1391770e+04, 3.6616842e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.3187690e+05,\n        9.9814710e+04, 3.6286136e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.3461546e+05,\n        1.4719887e+05, 1.2771682e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.3029813e+05,\n        1.4553006e+05, 3.2387668e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.2054252e+05,\n        1.4871895e+05, 3.1161329e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.2333488e+05,\n        1.0867917e+05, 3.0498162e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0191308e+05,\n        1.1059411e+05, 2.2916095e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0067196e+05,\n        9.1790610e+04, 2.4974455e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 9.3863750e+04,\n        1.2732038e+05, 2.4983944e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 9.1992390e+04,\n        1.3549507e+05, 2.5266493e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.1994324e+05,\n        1.5654742e+05, 2.5651292e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.1452361e+05,\n        1.2261684e+05, 2.6177623e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 7.8013110e+04,\n        1.2159755e+05, 2.6434606e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 9.4657160e+04,\n        1.4507758e+05, 2.8257431e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 9.1749160e+04,\n        1.1417579e+05, 2.9491957e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 8.6419700e+04,\n        1.5351411e+05, 0.0000000e+00],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 7.6253860e+04,\n        1.1386730e+05, 2.9866447e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.8389470e+04,\n        1.5377343e+05, 2.9973729e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 7.3994560e+04,\n        1.2278275e+05, 3.0331926e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.7532530e+04,\n        1.0575103e+05, 3.0476873e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.7044010e+04,\n        9.9281340e+04, 1.4057481e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 6.4664710e+04,\n        1.3955316e+05, 1.3796262e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 7.5328870e+04,\n        1.4413598e+05, 1.3405007e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.2107600e+04,\n        1.2786455e+05, 3.5318381e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.6051520e+04,\n        1.8264556e+05, 1.1814820e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 6.5605480e+04,\n        1.5303206e+05, 1.0713838e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.1994480e+04,\n        1.1564128e+05, 9.1131240e+04],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 6.1136380e+04,\n        1.5270192e+05, 8.8218230e+04],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 6.3408860e+04,\n        1.2921961e+05, 4.6085250e+04],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 5.5493950e+04,\n        1.0305749e+05, 2.1463481e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 4.6426070e+04,\n        1.5769392e+05, 2.1079767e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 4.6014020e+04,\n        8.5047440e+04, 2.0551764e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 2.8663760e+04,\n        1.2705621e+05, 2.0112682e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 4.4069950e+04,\n        5.1283140e+04, 1.9702942e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 2.0229590e+04,\n        6.5947930e+04, 1.8526510e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 3.8558510e+04,\n        8.2982090e+04, 1.7499930e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.8754330e+04,\n        1.1854605e+05, 1.7279567e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 2.7892920e+04,\n        8.4710770e+04, 1.6447071e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.3640930e+04,\n        9.6189630e+04, 1.4800111e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.5505730e+04,\n        1.2738230e+05, 3.5534170e+04],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.2177740e+04,\n        1.5480614e+05, 2.8334720e+04],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.0002300e+03,\n        1.2415304e+05, 1.9039300e+03],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.3154600e+03,\n        1.1581621e+05, 2.9711446e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        1.3542692e+05, 0.0000000e+00],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 5.4205000e+02,\n        5.1743150e+04, 0.0000000e+00],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        1.1698380e+05, 4.5173060e+04]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "array([[0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.6534920e+05,\n        1.3689780e+05, 4.7178410e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.6259770e+05,\n        1.5137759e+05, 4.4389853e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.5344151e+05,\n        1.0114555e+05, 4.0793454e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.4437241e+05,\n        1.1867185e+05, 3.8319962e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.4210734e+05,\n        9.1391770e+04, 3.6616842e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.3187690e+05,\n        9.9814710e+04, 3.6286136e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.3461546e+05,\n        1.4719887e+05, 1.2771682e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.3029813e+05,\n        1.4553006e+05, 3.2387668e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.2054252e+05,\n        1.4871895e+05, 3.1161329e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.2333488e+05,\n        1.0867917e+05, 3.0498162e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0191308e+05,\n        1.1059411e+05, 2.2916095e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0067196e+05,\n        9.1790610e+04, 2.4974455e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 9.3863750e+04,\n        1.2732038e+05, 2.4983944e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 9.1992390e+04,\n        1.3549507e+05, 2.5266493e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.1994324e+05,\n        1.5654742e+05, 2.5651292e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.1452361e+05,\n        1.2261684e+05, 2.6177623e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 7.8013110e+04,\n        1.2159755e+05, 2.6434606e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 9.4657160e+04,\n        1.4507758e+05, 2.8257431e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 9.1749160e+04,\n        1.1417579e+05, 2.9491957e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 8.6419700e+04,\n        1.5351411e+05, 0.0000000e+00],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 7.6253860e+04,\n        1.1386730e+05, 2.9866447e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.8389470e+04,\n        1.5377343e+05, 2.9973729e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 7.3994560e+04,\n        1.2278275e+05, 3.0331926e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.7532530e+04,\n        1.0575103e+05, 3.0476873e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.7044010e+04,\n        9.9281340e+04, 1.4057481e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 6.4664710e+04,\n        1.3955316e+05, 1.3796262e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 7.5328870e+04,\n        1.4413598e+05, 1.3405007e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.2107600e+04,\n        1.2786455e+05, 3.5318381e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.6051520e+04,\n        1.8264556e+05, 1.1814820e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 6.5605480e+04,\n        1.5303206e+05, 1.0713838e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.1994480e+04,\n        1.1564128e+05, 9.1131240e+04],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 6.1136380e+04,\n        1.5270192e+05, 8.8218230e+04],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 6.3408860e+04,\n        1.2921961e+05, 4.6085250e+04],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 5.5493950e+04,\n        1.0305749e+05, 2.1463481e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 4.6426070e+04,\n        1.5769392e+05, 2.1079767e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 4.6014020e+04,\n        8.5047440e+04, 2.0551764e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 2.8663760e+04,\n        1.2705621e+05, 2.0112682e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 4.4069950e+04,\n        5.1283140e+04, 1.9702942e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 2.0229590e+04,\n        6.5947930e+04, 1.8526510e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 3.8558510e+04,\n        8.2982090e+04, 1.7499930e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.8754330e+04,\n        1.1854605e+05, 1.7279567e+05],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 2.7892920e+04,\n        8.4710770e+04, 1.6447071e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.3640930e+04,\n        9.6189630e+04, 1.4800111e+05],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.5505730e+04,\n        1.2738230e+05, 3.5534170e+04],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.2177740e+04,\n        1.5480614e+05, 2.8334720e+04],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.0002300e+03,\n        1.2415304e+05, 1.9039300e+03],\n       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.3154600e+03,\n        1.1581621e+05, 2.9711446e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        1.3542692e+05, 0.0000000e+00],\n       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 5.4205000e+02,\n        5.1743150e+04, 0.0000000e+00],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        1.1698380e+05, 4.5173060e+04]])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "HS085G0Udfxa"
   },
   "outputs": [],
   "source": [
    "#sampling the dataset\n",
    "#normally 20% dataset is used for testing and 80% is used for training --> test_size=0.2 means 20%  \n",
    "#Training set will be used to train the model\n",
    "#Create Training and Testing sets\n",
    "# Testing set will be used to test our model\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(features,\n",
    "                                                label,\n",
    "                                                test_size=0.2,\n",
    "                                                random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "tyilNWsOdfxb",
    "outputId": "787102a5-98ec-4ac3-e874-abaa09cf93ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=18,\n                      max_features=None, max_leaf_nodes=None,\n                      min_impurity_decrease=0.0, min_impurity_split=None,\n                      min_samples_leaf=1, min_samples_split=2,\n                      min_weight_fraction_leaf=0.0, presort='deprecated',\n                      random_state=None, splitter='best')"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=18,\n                      max_features=None, max_leaf_nodes=None,\n                      min_impurity_decrease=0.0, min_impurity_split=None,\n                      min_samples_leaf=1, min_samples_split=2,\n                      min_weight_fraction_leaf=0.0, presort='deprecated',\n                      random_state=None, splitter='best')"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create our model using Linear Regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "DTR = DecisionTreeRegressor(max_depth=18)\n",
    "DTR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "5h2aNur1dfxb",
    "outputId": "fe951170-1f9d-4e30-eab7-584377de5113"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9583270520590703\n",
      "[101004.64 141585.52 141585.52  78239.91 182901.99 108733.99  69758.98\n",
      "  99937.59 108733.99 182901.99]\n",
      "1.0\n",
      "0.9741937370933437\n",
      "[101004.64 141585.52 141585.52  78239.91 182901.99 107404.34  69758.98\n",
      "  99937.59 108733.99 156991.12]\n"
     ]
    }
   ],
   "source": [
    "#checking score of training as well as testing\n",
    "print(DTR.score(X_train,y_train))\n",
    "print(DTR.score(X_test,y_test))\n",
    "print(DTR.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "E0RRKdn9dfxb",
    "outputId": "20049b71-941d-4137-a9c2-941775188d76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9884128255484982\n",
      "0.9596988206519019\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([104009.7152, 135076.058 , 135808.8228,  79913.0182, 181828.8523,\n       112581.2981,  68389.04  ,  99215.53  , 112213.9248, 168636.7459])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9895892182702438\n",
      "0.964690495442997\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([102927.2355, 135737.6098, 136663.4037,  79179.2744, 183618.6616,\n       112036.542 ,  68301.0641,  99425.5059, 111982.1148, 169231.9836])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RF=RandomForestRegressor(n_estimators=100)\n",
    "RF.fit(X_train,y_train.ravel())\n",
    "print(RF.score(X_train,y_train))\n",
    "print(RF.score(X_test,y_test))\n",
    "RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ZuaMtn7Idfxb",
    "outputId": "12930ce0-cfbf-4c65-b537-754d6d5f19a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimator =  20\n",
      "Training Score = 0.9893067360976529\n",
      "TEsting Score =  0.9598174168083468\n",
      "n_estimator =  21\n",
      "Training Score = 0.987103143860703\n",
      "TEsting Score =  0.9620768702755552\n",
      "n_estimator =  22\n",
      "Training Score = 0.9890670008650552\n",
      "TEsting Score =  0.9647047526602737\n",
      "n_estimator =  23\n",
      "Training Score = 0.987953434522295\n",
      "TEsting Score =  0.96695277683857\n",
      "n_estimator =  24\n",
      "Training Score = 0.9875924557834553\n",
      "TEsting Score =  0.9606062071733212\n",
      "n_estimator =  25\n",
      "Training Score = 0.9891303471382512\n",
      "TEsting Score =  0.9689840520558393\n",
      "n_estimator =  26\n",
      "Training Score = 0.9871709183797479\n",
      "TEsting Score =  0.965181877571757\n",
      "n_estimator =  27\n",
      "Training Score = 0.9889761130060061\n",
      "TEsting Score =  0.9656916626046439\n",
      "n_estimator =  28\n",
      "Training Score = 0.9885234101734041\n",
      "TEsting Score =  0.9672232401043637\n",
      "n_estimator =  29\n",
      "Training Score = 0.9883872365611075\n",
      "TEsting Score =  0.970762642981617\n",
      "n_estimator =  30\n",
      "Training Score = 0.9868222920271534\n",
      "TEsting Score =  0.9569184519766788\n",
      "n_estimator =  31\n",
      "Training Score = 0.9880322962604685\n",
      "TEsting Score =  0.9617069569284191\n",
      "n_estimator =  32\n",
      "Training Score = 0.9902130814883703\n",
      "TEsting Score =  0.9655354600145202\n",
      "n_estimator =  33\n",
      "Training Score = 0.9897787742643979\n",
      "TEsting Score =  0.9684238306215475\n",
      "n_estimator =  34\n",
      "Training Score = 0.9852049814821423\n",
      "TEsting Score =  0.9656925328175523\n",
      "n_estimator =  35\n",
      "Training Score = 0.9889579201563704\n",
      "TEsting Score =  0.958540120409812\n",
      "n_estimator =  36\n",
      "Training Score = 0.9891436509369227\n",
      "TEsting Score =  0.9673283452637449\n",
      "n_estimator =  37\n",
      "Training Score = 0.9883457361224273\n",
      "TEsting Score =  0.9642086829750242\n",
      "n_estimator =  38\n",
      "Training Score = 0.9889319221972201\n",
      "TEsting Score =  0.9637884827024691\n",
      "n_estimator =  39\n",
      "Training Score = 0.9874012894730836\n",
      "TEsting Score =  0.9662096308098077\n",
      "n_estimator =  40\n",
      "Training Score = 0.989063813555807\n",
      "TEsting Score =  0.962022684459448\n",
      "n_estimator =  41\n",
      "Training Score = 0.9879851825311904\n",
      "TEsting Score =  0.9691252951921541\n",
      "n_estimator =  42\n",
      "Training Score = 0.9876066166064561\n",
      "TEsting Score =  0.9635677919065971\n",
      "n_estimator =  43\n",
      "Training Score = 0.9887258189798107\n",
      "TEsting Score =  0.9647675184011518\n",
      "n_estimator =  44\n",
      "Training Score = 0.9886057085245531\n",
      "TEsting Score =  0.9542805377687199\n",
      "n_estimator =  45\n",
      "Training Score = 0.9862770869328763\n",
      "TEsting Score =  0.9623543868801346\n",
      "n_estimator =  46\n",
      "Training Score = 0.9879454961591131\n",
      "TEsting Score =  0.9686373660757849\n",
      "n_estimator =  47\n",
      "Training Score = 0.9897053894644418\n",
      "TEsting Score =  0.9711666007099118\n",
      "n_estimator =  48\n",
      "Training Score = 0.9904281264221128\n",
      "TEsting Score =  0.9604181466959483\n",
      "n_estimator =  49\n",
      "Training Score = 0.9864417412955004\n",
      "TEsting Score =  0.9645013925466744\n",
      "n_estimator =  50\n",
      "Training Score = 0.9901791952861387\n",
      "TEsting Score =  0.9680160269203214\n",
      "n_estimator =  51\n",
      "Training Score = 0.9871656450292139\n",
      "TEsting Score =  0.9639683150449126\n",
      "n_estimator =  52\n",
      "Training Score = 0.9899705366510626\n",
      "TEsting Score =  0.9679784493685955\n",
      "n_estimator =  53\n",
      "Training Score = 0.9895165033013276\n",
      "TEsting Score =  0.967396938020138\n",
      "n_estimator =  54\n",
      "Training Score = 0.9898427105755891\n",
      "TEsting Score =  0.957474846919733\n",
      "n_estimator =  55\n",
      "Training Score = 0.9877862265576264\n",
      "TEsting Score =  0.9612012539968738\n",
      "n_estimator =  56\n",
      "Training Score = 0.986649293686663\n",
      "TEsting Score =  0.9645647201289383\n",
      "n_estimator =  57\n",
      "Training Score = 0.9884687471930264\n",
      "TEsting Score =  0.9617273523399054\n",
      "n_estimator =  58\n",
      "Training Score = 0.9883557616147859\n",
      "TEsting Score =  0.9573882396541246\n",
      "n_estimator =  59\n",
      "Training Score = 0.9851886425853584\n",
      "TEsting Score =  0.971232799231353\n",
      "n_estimator =  60\n",
      "Training Score = 0.9882933504783544\n",
      "TEsting Score =  0.9641333192339806\n",
      "n_estimator =  61\n",
      "Training Score = 0.9855312461263748\n",
      "TEsting Score =  0.9651985096658057\n",
      "n_estimator =  62\n",
      "Training Score = 0.9881729095130513\n",
      "TEsting Score =  0.9653713275007791\n",
      "n_estimator =  63\n",
      "Training Score = 0.9867315380198362\n",
      "TEsting Score =  0.9692132299357171\n",
      "n_estimator =  64\n",
      "Training Score = 0.9891363574805421\n",
      "TEsting Score =  0.9619205496127295\n",
      "n_estimator =  65\n",
      "Training Score = 0.9888042647169822\n",
      "TEsting Score =  0.9723204503338415\n",
      "n_estimator =  66\n",
      "Training Score = 0.9887295238823721\n",
      "TEsting Score =  0.9607793691809418\n",
      "n_estimator =  67\n",
      "Training Score = 0.9872317420562126\n",
      "TEsting Score =  0.9652363159854347\n",
      "n_estimator =  68\n",
      "Training Score = 0.989123510815253\n",
      "TEsting Score =  0.9579424455843059\n",
      "n_estimator =  69\n",
      "Training Score = 0.9852047231893456\n",
      "TEsting Score =  0.9623868805649562\n",
      "n_estimator =  70\n",
      "Training Score = 0.9890811517973581\n",
      "TEsting Score =  0.9623955094746648\n",
      "n_estimator =  71\n",
      "Training Score = 0.9861435965156627\n",
      "TEsting Score =  0.9602711990459744\n",
      "n_estimator =  72\n",
      "Training Score = 0.9866352142882535\n",
      "TEsting Score =  0.9661904529852277\n",
      "n_estimator =  73\n",
      "Training Score = 0.9895899732747738\n",
      "TEsting Score =  0.955444303224336\n",
      "n_estimator =  74\n",
      "Training Score = 0.9890232120797575\n",
      "TEsting Score =  0.9600489507107299\n",
      "n_estimator =  75\n",
      "Training Score = 0.9870286080338752\n",
      "TEsting Score =  0.9645543249932849\n",
      "n_estimator =  76\n",
      "Training Score = 0.9890600032820419\n",
      "TEsting Score =  0.967585701287757\n",
      "n_estimator =  77\n",
      "Training Score = 0.9865916812194448\n",
      "TEsting Score =  0.9660619480928203\n",
      "n_estimator =  78\n",
      "Training Score = 0.987520254134296\n",
      "TEsting Score =  0.9679898301524836\n",
      "n_estimator =  79\n",
      "Training Score = 0.9875756540161214\n",
      "TEsting Score =  0.961332182713881\n",
      "n_estimator =  80\n",
      "Training Score = 0.9884778416063321\n",
      "TEsting Score =  0.9579552794189539\n",
      "n_estimator =  81\n",
      "Training Score = 0.989545425873144\n",
      "TEsting Score =  0.9648049049511338\n",
      "n_estimator =  82\n",
      "Training Score = 0.9884929572750853\n",
      "TEsting Score =  0.9636742359300501\n",
      "n_estimator =  83\n",
      "Training Score = 0.9880315875035919\n",
      "TEsting Score =  0.9637237219196558\n",
      "n_estimator =  84\n",
      "Training Score = 0.9872651123292747\n",
      "TEsting Score =  0.9683044013760934\n",
      "n_estimator =  85\n",
      "Training Score = 0.9859369865540397\n",
      "TEsting Score =  0.9649031559456078\n",
      "n_estimator =  86\n",
      "Training Score = 0.9882354103586539\n",
      "TEsting Score =  0.9569351671466626\n",
      "n_estimator =  87\n",
      "Training Score = 0.9880837396148159\n",
      "TEsting Score =  0.9560782268617176\n",
      "n_estimator =  88\n",
      "Training Score = 0.9885330027073972\n",
      "TEsting Score =  0.965786970275444\n",
      "n_estimator =  89\n",
      "Training Score = 0.9868350270738947\n",
      "TEsting Score =  0.9634017818153122\n",
      "n_estimator =  90\n",
      "Training Score = 0.9885089214732486\n",
      "TEsting Score =  0.9576662337981549\n",
      "n_estimator =  91\n",
      "Training Score = 0.9896076539558245\n",
      "TEsting Score =  0.9624844605683812\n",
      "n_estimator =  92\n",
      "Training Score = 0.9877965730682248\n",
      "TEsting Score =  0.962389755920704\n",
      "n_estimator =  93\n",
      "Training Score = 0.9881910095051128\n",
      "TEsting Score =  0.9626837703498818\n",
      "n_estimator =  94\n",
      "Training Score = 0.9894355441321367\n",
      "TEsting Score =  0.9696399593727444\n",
      "n_estimator =  95\n",
      "Training Score = 0.9867876879326061\n",
      "TEsting Score =  0.9669190786282558\n",
      "n_estimator =  96\n",
      "Training Score = 0.9877567521972639\n",
      "TEsting Score =  0.9711566665245709\n",
      "n_estimator =  97\n",
      "Training Score = 0.9876910324826723\n",
      "TEsting Score =  0.9607312503559711\n",
      "n_estimator =  98\n",
      "Training Score = 0.9882477803900331\n",
      "TEsting Score =  0.9620952851906402\n",
      "n_estimator =  99\n",
      "Training Score = 0.9873228066532056\n",
      "TEsting Score =  0.9640015271454941\n",
      "n_estimator =  20\n",
      "Training Score = 0.9868792411697586\n",
      "TEsting Score =  0.9680333821547676\n",
      "n_estimator =  21\n",
      "Training Score = 0.9867645656468491\n",
      "TEsting Score =  0.9644455413760298\n",
      "n_estimator =  22\n",
      "Training Score = 0.9882902326253458\n",
      "TEsting Score =  0.9635810328846955\n",
      "n_estimator =  23\n",
      "Training Score = 0.9883276470811968\n",
      "TEsting Score =  0.9682680153933293\n",
      "n_estimator =  24\n",
      "Training Score = 0.9850096560307265\n",
      "TEsting Score =  0.9649307065096848\n",
      "n_estimator =  25\n",
      "Training Score = 0.9866441516699856\n",
      "TEsting Score =  0.9676849466913556\n",
      "n_estimator =  26\n",
      "Training Score = 0.9890427724558717\n",
      "TEsting Score =  0.9623164459536562\n",
      "n_estimator =  27\n",
      "Training Score = 0.9897095217878616\n",
      "TEsting Score =  0.9620748818666914\n",
      "n_estimator =  28\n",
      "Training Score = 0.9883894896971482\n",
      "TEsting Score =  0.9628001354156187\n",
      "n_estimator =  29\n",
      "Training Score = 0.9888628073622725\n",
      "TEsting Score =  0.9646608994953811\n",
      "n_estimator =  30\n",
      "Training Score = 0.9904718544496092\n",
      "TEsting Score =  0.9631042986149501\n",
      "n_estimator =  31\n",
      "Training Score = 0.9889570246555309\n",
      "TEsting Score =  0.9598053945399403\n",
      "n_estimator =  32\n",
      "Training Score = 0.9859448870593646\n",
      "TEsting Score =  0.9689395964768092\n",
      "n_estimator =  33\n",
      "Training Score = 0.987784097819208\n",
      "TEsting Score =  0.9660559458989312\n",
      "n_estimator =  34\n",
      "Training Score = 0.9880261295286776\n",
      "TEsting Score =  0.9717276706948939\n",
      "n_estimator =  35\n",
      "Training Score = 0.9853685943988556\n",
      "TEsting Score =  0.9638611926426774\n",
      "n_estimator =  36\n",
      "Training Score = 0.9873903007931071\n",
      "TEsting Score =  0.9671042757842903\n",
      "n_estimator =  37\n",
      "Training Score = 0.9873267986054897\n",
      "TEsting Score =  0.9661421722165284\n",
      "n_estimator =  38\n",
      "Training Score = 0.9868563142629504\n",
      "TEsting Score =  0.9629861661590908\n",
      "n_estimator =  39\n",
      "Training Score = 0.9889743914575936\n",
      "TEsting Score =  0.9676453045107923\n",
      "n_estimator =  40\n",
      "Training Score = 0.986547564020269\n",
      "TEsting Score =  0.9595196367803498\n",
      "n_estimator =  41\n",
      "Training Score = 0.986663906954128\n",
      "TEsting Score =  0.9609743326195269\n",
      "n_estimator =  42\n",
      "Training Score = 0.9892055450716865\n",
      "TEsting Score =  0.959550236308556\n",
      "n_estimator =  43\n",
      "Training Score = 0.9880439359974506\n",
      "TEsting Score =  0.9620700938143473\n",
      "n_estimator =  44\n",
      "Training Score = 0.9866905099760722\n",
      "TEsting Score =  0.9629568777828278\n",
      "n_estimator =  45\n",
      "Training Score = 0.9888663064463565\n",
      "TEsting Score =  0.9623483654405991\n",
      "n_estimator =  46\n",
      "Training Score = 0.9891237407353003\n",
      "TEsting Score =  0.9605575885411615\n",
      "n_estimator =  47\n",
      "Training Score = 0.9884855340767603\n",
      "TEsting Score =  0.9647886773653902\n",
      "n_estimator =  48\n",
      "Training Score = 0.9876660114186088\n",
      "TEsting Score =  0.9653514707092073\n",
      "n_estimator =  49\n",
      "Training Score = 0.9890526175274362\n",
      "TEsting Score =  0.9718398109759362\n",
      "n_estimator =  50\n",
      "Training Score = 0.9879602852151\n",
      "TEsting Score =  0.9666837276977247\n",
      "n_estimator =  51\n",
      "Training Score = 0.9890156367787327\n",
      "TEsting Score =  0.9696737280733232\n",
      "n_estimator =  52\n",
      "Training Score = 0.988544850395661\n",
      "TEsting Score =  0.9652006388036082\n",
      "n_estimator =  53\n",
      "Training Score = 0.9890818421809895\n",
      "TEsting Score =  0.9583818651410927\n",
      "n_estimator =  54\n",
      "Training Score = 0.9887792134639827\n",
      "TEsting Score =  0.9697812473214107\n",
      "n_estimator =  55\n",
      "Training Score = 0.9876889646439593\n",
      "TEsting Score =  0.9679097388805766\n",
      "n_estimator =  56\n",
      "Training Score = 0.9874071719064753\n",
      "TEsting Score =  0.9614558182782743\n",
      "n_estimator =  57\n",
      "Training Score = 0.9880612338337843\n",
      "TEsting Score =  0.9612405223171447\n",
      "n_estimator =  58\n",
      "Training Score = 0.9887872509515941\n",
      "TEsting Score =  0.962295507969256\n",
      "n_estimator =  59\n",
      "Training Score = 0.9886001284711045\n",
      "TEsting Score =  0.9632031170187713\n",
      "n_estimator =  60\n",
      "Training Score = 0.9892042184109411\n",
      "TEsting Score =  0.9600062593862249\n",
      "n_estimator =  61\n",
      "Training Score = 0.9870809529346564\n",
      "TEsting Score =  0.9623305136871632\n",
      "n_estimator =  62\n",
      "Training Score = 0.9880916172542009\n",
      "TEsting Score =  0.9675945558389553\n",
      "n_estimator =  63\n",
      "Training Score = 0.9879995974621988\n",
      "TEsting Score =  0.9618220727292437\n",
      "n_estimator =  64\n",
      "Training Score = 0.9887594226006209\n",
      "TEsting Score =  0.9641509098378823\n",
      "n_estimator =  65\n",
      "Training Score = 0.9882401140387393\n",
      "TEsting Score =  0.9635232605049207\n",
      "n_estimator =  66\n",
      "Training Score = 0.9878675396094354\n",
      "TEsting Score =  0.9625595253857487\n",
      "n_estimator =  67\n",
      "Training Score = 0.9871518549307743\n",
      "TEsting Score =  0.967044448406668\n",
      "n_estimator =  68\n",
      "Training Score = 0.9887411177633048\n",
      "TEsting Score =  0.9591951357776823\n",
      "n_estimator =  69\n",
      "Training Score = 0.99016880087361\n",
      "TEsting Score =  0.9605846734012848\n",
      "n_estimator =  70\n",
      "Training Score = 0.9888613312590179\n",
      "TEsting Score =  0.9641864622004616\n",
      "n_estimator =  71\n",
      "Training Score = 0.9872263120601495\n",
      "TEsting Score =  0.956875011709622\n",
      "n_estimator =  72\n",
      "Training Score = 0.986793670286939\n",
      "TEsting Score =  0.9687512332125565\n",
      "n_estimator =  73\n",
      "Training Score = 0.9870218744599542\n",
      "TEsting Score =  0.9635225764798726\n",
      "n_estimator =  74\n",
      "Training Score = 0.9889361560926366\n",
      "TEsting Score =  0.9615227399993442\n",
      "n_estimator =  75\n",
      "Training Score = 0.9891443375159903\n",
      "TEsting Score =  0.9623460371570158\n",
      "n_estimator =  76\n",
      "Training Score = 0.9880274134390632\n",
      "TEsting Score =  0.9702675508035494\n",
      "n_estimator =  77\n",
      "Training Score = 0.9877802619671586\n",
      "TEsting Score =  0.960159657673629\n",
      "n_estimator =  78\n",
      "Training Score = 0.9876526341027838\n",
      "TEsting Score =  0.9643839387083593\n",
      "n_estimator =  79\n",
      "Training Score = 0.9864735548907364\n",
      "TEsting Score =  0.9676292291167551\n",
      "n_estimator =  80\n",
      "Training Score = 0.9862054931935083\n",
      "TEsting Score =  0.9633287239225083\n",
      "n_estimator =  81\n",
      "Training Score = 0.9878960285279983\n",
      "TEsting Score =  0.965904201180634\n",
      "n_estimator =  82\n",
      "Training Score = 0.9880652479552976\n",
      "TEsting Score =  0.9595988299023501\n",
      "n_estimator =  83\n",
      "Training Score = 0.9896992124947672\n",
      "TEsting Score =  0.9642166635750804\n",
      "n_estimator =  84\n",
      "Training Score = 0.9875809050279762\n",
      "TEsting Score =  0.9610981126199998\n",
      "n_estimator =  85\n",
      "Training Score = 0.9888588017767699\n",
      "TEsting Score =  0.961179245807194\n",
      "n_estimator =  86\n",
      "Training Score = 0.9897131142862088\n",
      "TEsting Score =  0.9740395242046744\n",
      "n_estimator =  87\n",
      "Training Score = 0.988273652756264\n",
      "TEsting Score =  0.9634896606645745\n",
      "n_estimator =  88\n",
      "Training Score = 0.9901822558082637\n",
      "TEsting Score =  0.9701433597981792\n",
      "n_estimator =  89\n",
      "Training Score = 0.9888059026237909\n",
      "TEsting Score =  0.9556891217139714\n",
      "n_estimator =  90\n",
      "Training Score = 0.9874926728069068\n",
      "TEsting Score =  0.9673952896415821\n",
      "n_estimator =  91\n",
      "Training Score = 0.9898560779548176\n",
      "TEsting Score =  0.9601617783241986\n",
      "n_estimator =  92\n",
      "Training Score = 0.9887360349282462\n",
      "TEsting Score =  0.968810987151615\n",
      "n_estimator =  93\n",
      "Training Score = 0.9883556363577157\n",
      "TEsting Score =  0.9641638489391898\n",
      "n_estimator =  94\n",
      "Training Score = 0.9881616913166058\n",
      "TEsting Score =  0.9597214854598375\n",
      "n_estimator =  95\n",
      "Training Score = 0.9875966678784585\n",
      "TEsting Score =  0.9620293165954148\n",
      "n_estimator =  96\n",
      "Training Score = 0.985643680980432\n",
      "TEsting Score =  0.9698004869091982\n",
      "n_estimator =  97\n",
      "Training Score = 0.9889112322589861\n",
      "TEsting Score =  0.9672483031407934\n",
      "n_estimator =  98\n",
      "Training Score = 0.9867345555041609\n",
      "TEsting Score =  0.9540545386692337\n",
      "n_estimator =  99\n",
      "Training Score = 0.9896115095603096\n",
      "TEsting Score =  0.9643023641383366\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "for i in range(20,100):\n",
    "    RF=RandomForestRegressor(n_estimators=100)\n",
    "    RF.fit(X_train,y_train.ravel())\n",
    "    print(\"n_estimator = \",i)\n",
    "    print(\"Training Score =\",RF.score(X_train,y_train))\n",
    "    print(\"TEsting Score = \",RF.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg= LinearRegression()\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9501847627493607\n",
      "0.9347068473282303\n",
      "[[103015.20159796]\n",
      " [132582.27760816]\n",
      " [132447.73845174]\n",
      " [ 71976.09851258]\n",
      " [178537.48221055]\n",
      " [116161.24230166]\n",
      " [ 67851.69209676]\n",
      " [ 98791.73374686]\n",
      " [113969.43533013]\n",
      " [167921.06569551]]\n",
      "0.9501847627493607\n",
      "0.9347068473282303\n",
      "[[103015.20159796]\n",
      " [132582.27760816]\n",
      " [132447.73845174]\n",
      " [ 71976.09851258]\n",
      " [178537.48221055]\n",
      " [116161.24230166]\n",
      " [ 67851.69209676]\n",
      " [ 98791.73374686]\n",
      " [113969.43533013]\n",
      " [167921.06569551]]\n"
     ]
    }
   ],
   "source": [
    "print(reg.score(X_train, y_train))\n",
    "print(reg.score(X_test, y_test))\n",
    "print(reg.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "DecisionTree_RandomForest_Regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}